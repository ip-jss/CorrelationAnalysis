{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Exclusions **\n",
    "This is a short noteboook that will calculate the exclusions from the aggregated bi-section task data. \n",
    "To run the the analysis click on each block of code and then click the run icon on the toolbar at the top. Alternatively, click a code block and press shift-enter. [Click for here for help](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Running%20Code.html)\n",
    "\n",
    "If any errors such as \"No module named XXX\" occur, please install the module. Its much easier to use just download anaconda, which comes with the relevant libraries pre-packaged. \n",
    "\n",
    "*Refer to the [Exclusion criterion notebook](Exclusion criterion .ipynb) for a detailed walkthrough.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "import math \n",
    "import pylab \n",
    "from scipy import stats\n",
    "\n",
    "from statsmodels import robust\n",
    "\n",
    "import colorama\n",
    "from colorama import Fore\n",
    "\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "## *Getting the data*\n",
    "This section will get the data from your disk. Ensure that you fill the file path prompt correctly, otherwise there will be nothing to work with.\n",
    "\n",
    "__[How to get a file-path on a mac](https://apple.stackexchange.com/questions/252171/mac-finder-getting-the-path-of-a-directory-or-file-as-as-string)__\n",
    "<br> __[How to get a file-path on windows](https://stackoverflow.com/questions/32573080/how-can-i-get-the-path-to-a-file-in-windows-10)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What condition is this?\n",
      "Gamma 3\n",
      "What is the file path?\n",
      "/Users/Akshi/Desktop/Correlation/Correlation_Analysis/Data/Gamma 3.0 Final Analysis (with reruns).xlsm\n"
     ]
    }
   ],
   "source": [
    "print(\"What condition is this?\")\n",
    "condition_name = input()\n",
    "print(\"What is the file path?\")\n",
    "file_path = input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the above file path is correct before running the next block of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read the data *** Make sure path is set to the correct file-path *** \n",
    "path = file_path\n",
    "data_sheet = pd.ExcelFile(path)\n",
    "\n",
    "#Parse the Exclusions sheet to create a Pandas DataFrame\n",
    "exlcusions = data_sheet.parse('1. Exclusions')\n",
    "#Select the columns that are needed and create a new DataFrame with them\n",
    "DF = exlcusions[[\"ID\",\"subCondition\",\"highRef\",\"estimatedMid\",\"lowRef\",\"roundType\", \"AnchorValues\"]]\n",
    "#Drop NaN values\n",
    "DF = DF.dropna(subset=[\"estimatedMid\"])\n",
    "\n",
    "#Group the DataFrame by subcondition\n",
    "sub_cond_df = DF.groupby(\"subCondition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "## *Functions*\n",
    "The next code block contains the helper and main functions that will be used to conduct the analysis. \n",
    "Ensure that this block is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to transform the data. Either box-cox or cbrt transforms are applied after acconting for anchoring\n",
    "\n",
    "def transform(sub_cond):\n",
    "    '''A function that combines attempts for a subcondition, in order to account for anchoring.\n",
    "        Returns a numpy array with transformed data. Resulting distribution should be Gaussian.\n",
    "        \n",
    "        @param sub_cond: subconditon that will be transformed\n",
    "        @return uni_modal: np.array with transformed data'''\n",
    "    \n",
    "    #0 corresponds to first attempt \n",
    "    first_idx = 0 \n",
    "    second_idx = 1\n",
    "    third_idx = 2\n",
    "    fourth_idx = 3 \n",
    "    \n",
    "    #Get estimatedMid column from DataFrame\n",
    "    estimates = sub_cond['estimatedMid']\n",
    "    \n",
    "    #Create a np-array for transformed data\n",
    "    uni_modal= np.empty(int(len(sub_cond)/4))\n",
    "    \n",
    "    for i in range(int(len(sub_cond)/4)):\n",
    "        #Get attempts for a participant\n",
    "        first_atmpt = estimates.iloc[first_idx]\n",
    "        second_atmpt = estimates.iloc[second_idx]\n",
    "        third_atmpt = estimates.iloc[third_idx]\n",
    "        fourth_atmpt = estimates.iloc[fourth_idx]\n",
    "        #Calculate new estimate via Spencers suggested formula\n",
    "        estimate = abs(((first_atmpt+third_atmpt) - (second_atmpt+fourth_atmpt)))\n",
    "        #Add to np-array\n",
    "        uni_modal[i] = estimate\n",
    "        #Increase index to next participant\n",
    "        first_idx+=4\n",
    "        second_idx+=4\n",
    "        third_idx+=4\n",
    "        fourth_idx+=4\n",
    "    \n",
    "        \n",
    "    #return transformed data \n",
    "    return uni_modal\n",
    "\n",
    "\n",
    "\n",
    "def cbrt(data):\n",
    "    '''function that applys a cubroot transform and returns the array\n",
    "        @param data : array of estimates that are going to be transformed\n",
    "        @return measurements: array with transforemd data '''\n",
    "    \n",
    "    #Apply cubroot transform \n",
    "    measurements = (data**(1/3))\n",
    "     \n",
    "    #return transformed data \n",
    "    return measurements\n",
    "\n",
    "\n",
    "def box_cox(data):\n",
    "    '''function that preforms box-cox transform and returns the array\n",
    "        @param data : array of estimates that are going to be transformed\n",
    "        @return measurements: array with transforemd data '''\n",
    "    \n",
    "    #Apply cubroot transform \n",
    "    measurements = stats.boxcox(data, 0)\n",
    "\n",
    "    #return transformed data \n",
    "    return measurements\n",
    "\n",
    "\n",
    "#End of transformation functions\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#A function that tests for normality of data\n",
    "\n",
    "def norm_test(data, alpha):\n",
    "    '''function that determines if the given data is normal or not\n",
    "    @param data: array containg the data that will have K^2 test applied to it\n",
    "    @param alpha: significane level (default is 0.05)\n",
    "    @return normal,stat,p: stat is boolean signifying if data is normally distributed or not. HO sample is Gaussian. Result are results of the test'''\n",
    "    \n",
    "    normal = True \n",
    "    \n",
    "    #K^2 test\n",
    "    stat, p = stats.normaltest(data)\n",
    "    \n",
    "    #Print results\n",
    "    print('\\033[0m'+  Fore.BLUE + 'Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "    \n",
    "    # interpret p value\n",
    "    \n",
    "    if( p > 0.05):\n",
    "        print('\\033[0m' + Fore.BLUE+ 'Sample looks Gaussian (fail to reject H0)')\n",
    "    else:\n",
    "        print('\\033[0m'+ Fore.RED + 'SAMPLE NOT GAUSSIAN!!!!'  + '(reject H0)')\n",
    "        normal = False\n",
    "    print('\\033[0m' + Fore.BLUE + \"---------------------------------\")\n",
    "    \n",
    "    return [normal,stat,p]\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#Functions to get Robust score and exclusions\n",
    "\n",
    "def get_score(data):\n",
    "    '''Function to calculate RobustScore, defined as: RS = (x - median)/MAD, where MAD is Medium Absolutle Deviation\n",
    "        @param data: array for which score will be calculated\n",
    "        @return score_list: np array containg RS for each data point'''\n",
    "    \n",
    "    #empty numpy array \n",
    "    score_list = np.empty(len(data))\n",
    "    \n",
    "    #calculate MAD and median\n",
    "    mad = robust.scale.mad(data)\n",
    "    median = np.median(data)\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        #Calculate score for each data point\n",
    "        num = (data[i]-median)\n",
    "        denom = mad\n",
    "        score = num/denom\n",
    "        #add to list\n",
    "        score_list[i] = score\n",
    "        \n",
    "    return score_list\n",
    "\n",
    "def exclusion(data):\n",
    "    '''Function that calculate the exclusions for an array and returns the IDs of participants that should be excluded\n",
    "        @param data :data for which exclusions will get calculated\n",
    "        @return IDs : np array containg IDs of participants that should be excluded'''\n",
    "    \n",
    "    #exclusions_idx contains the indicies of any participants for the given subconditon that should be excluded \n",
    "    exclusions_idx = []\n",
    "\n",
    "    #get robust score\n",
    "    data_score = np.abs(np.array(get_score(data)))\n",
    "    \n",
    "    #get indicies of exclusions\n",
    "    exclusions_idx = np.where(data_score > 2.5)[0].tolist()\n",
    "    \n",
    "    #increment index to match participant IDs if there are any exclusions\n",
    "    IDs =  exclusions_idx\n",
    "    if(IDs):\n",
    "        ID = [x+1 for x in IDs]\n",
    "        IDs = ID\n",
    "    \n",
    "    \n",
    "\n",
    "    return IDs \n",
    "\n",
    "        \n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#General purpose ploting function\n",
    "def dist_plotter(measurements, sub_condition, transformed=False):\n",
    "    '''Function to plot the distribution and Normal QQ\n",
    "        @param measurements: np array of vlaues that will be plotted\n",
    "        @param sub_condition: int sub_condition being plotted  \n",
    "        @param transformed: bool, default is False. Set to True is plotting transformed data'''\n",
    "    \n",
    "    #plot histogram\n",
    "    plt.subplot(1,2,1)\n",
    "    sns.distplot(measurements, kde=False)\n",
    "    if(transformed):\n",
    "        plt.title(\"Subcondition \" + sub_condition + \" transformed data\")\n",
    "    else: \n",
    "         plt.title(\"Subcondition \" + sub_condition + \" raw data\")\n",
    "    #Normal QQ plot\n",
    "    plt.subplot(1,2,2)\n",
    "    stats.probplot(measurements, dist=\"norm\", plot=plt)\n",
    "    plt.title(\"Subcondition \" + sub_condition + \" QQ plot\")\n",
    "    plt.show()\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------\n",
    "#Main function that will be called to do the analysis work\n",
    "def analyse():\n",
    "    '''Main function that will calls relevant helpers'''\n",
    "    \n",
    "    #Create a DF for the output\n",
    "    columns = [\"Subcondition\", \"Statistic\", \"p-value\", \"Gaussian\",\"Exclusions\"]\n",
    "    exclusions_df = pd.DataFrame(columns=columns)\n",
    "    exclusions_df.fillna(0) \n",
    "    \n",
    "    for i in range(1,16):\n",
    "        #Get subcondition\n",
    "        sub_cond = sub_cond_df.get_group(i)\n",
    "        #transform\n",
    "        transformed = transform(sub_cond)\n",
    "        #normalise\n",
    "        normal_data = cbrt(transformed)\n",
    "        #test for normality\n",
    "        print('\\033[1m' + '\\033[4m' + Fore.BLUE + \"Subconditon \" + str(i)) \n",
    "        \n",
    "        #Add subcond to DF\n",
    "        exclusions_df.at[i-1,'Subcondition'] = i\n",
    "        \n",
    "        norm = norm_test(normal_data, 0.05)\n",
    "        _gaussian = norm[0]\n",
    "        stat = norm[1]\n",
    "        p_val = norm[2]\n",
    "        \n",
    "        exclusions_df.at[i-1,\"Statistic\"]= stat\n",
    "        exclusions_df.at[i-1,\"p-value\"] = p_val\n",
    "        exclusions_df.at[i-1,\"Gaussian\"] = _gaussian\n",
    "        \n",
    "        #commented this out for now. Should try to fix later\n",
    "        #if( _gaussian != True):\n",
    "        #    print(Fore.RED + \"box_cox applied\")\n",
    "        #    normal_data = box_cox(transformed)\n",
    "        #    _norm2 = norm_test(normal_data,0.05)\n",
    "            \n",
    "        #    count = 5\n",
    "        #     while(_norm2 != True): \n",
    "        #            print(Fore.BLUE+ \"Sample still not normal, enter lower sigfincance level\")\n",
    "        #           alpha_lvl = input()\n",
    "        #            normal_data = box_cox(transformed)\n",
    "        #            _norm2 = norm_test(normal_data,alpha_lvl)\n",
    "        #            count -= 1\n",
    "        #            if(count == 0):\n",
    "        #                print(Fore.RED+ \"Sample is problematic, be careful before proceding further\")\n",
    "        #               break\n",
    "            \n",
    "        #Get RS\n",
    "        scores = get_score(normal_data)\n",
    "        #get exclusions\n",
    "        exclusions = exclusion(scores)\n",
    "        if(exclusions):\n",
    "            string =  ', '.join(str(x) for x in exclusions)\n",
    "        else: string = \"No exclusions\"\n",
    "        exclusions_df.at[i-1,\"Exclusions\"] = string\n",
    "        \n",
    "        if exclusions:\n",
    "            print('\\033[0m' +  Fore.RED + \"Exclude participant(s): \"  , end='' )\n",
    "            print(*exclusions, sep=',')\n",
    "            print('\\n' )\n",
    "        else: \n",
    "            print('\\033[0m' + Fore.GREEN+\"No exclusions\" )\n",
    "            print('\\n')\n",
    "            print('\\n' )\n",
    "    \n",
    "   \n",
    "    pd.set_option('colheader_justify', 'center')\n",
    "    html_string = '''<html>\n",
    "      <head><title>Exclusions table</title></head>\n",
    "      <link rel=\"stylesheet\" type=\"text/css\" href=\"main.css\"/>\n",
    "      <body>\n",
    "        {table}\n",
    "      </body>\n",
    "    </html>. '''\n",
    "    \n",
    "    with open(condition_name+ ' Exclusions' + '.html', 'w') as f:\n",
    "        f.write(html_string.format(table= exclusions_df.to_html(classes='df style', index=False)))\n",
    "    \n",
    "    #pdfkit.from_file( condition_name + '.html' , 'Analysis of ' + condition_name + '.pdf')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next block of code to get exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 1\n",
      "\u001b[0m\u001b[34mStatistics=5.889, p=0.053\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[32mNo exclusions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 2\n",
      "\u001b[0m\u001b[34mStatistics=0.038, p=0.981\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[32mNo exclusions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 3\n",
      "\u001b[0m\u001b[34mStatistics=2.855, p=0.240\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[32mNo exclusions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 4\n",
      "\u001b[0m\u001b[34mStatistics=0.744, p=0.689\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[32mNo exclusions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 5\n",
      "\u001b[0m\u001b[34mStatistics=1.901, p=0.386\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[31mExclude participant(s): 4,5\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 6\n",
      "\u001b[0m\u001b[34mStatistics=2.054, p=0.358\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[32mNo exclusions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 7\n",
      "\u001b[0m\u001b[34mStatistics=2.604, p=0.272\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[31mExclude participant(s): 15\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 8\n",
      "\u001b[0m\u001b[34mStatistics=3.240, p=0.198\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[31mExclude participant(s): 3,6\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 9\n",
      "\u001b[0m\u001b[34mStatistics=1.350, p=0.509\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[32mNo exclusions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 10\n",
      "\u001b[0m\u001b[34mStatistics=7.553, p=0.023\n",
      "\u001b[0m\u001b[31mSAMPLE NOT GAUSSIAN!!!!(reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[31mExclude participant(s): 5,6,8\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 11\n",
      "\u001b[0m\u001b[34mStatistics=0.226, p=0.893\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[32mNo exclusions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 12\n",
      "\u001b[0m\u001b[34mStatistics=2.909, p=0.234\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[31mExclude participant(s): 3\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 13\n",
      "\u001b[0m\u001b[34mStatistics=4.818, p=0.090\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[31mExclude participant(s): 7\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 14\n",
      "\u001b[0m\u001b[34mStatistics=0.461, p=0.794\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[32mNo exclusions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[4m\u001b[34mSubconditon 15\n",
      "\u001b[0m\u001b[34mStatistics=0.368, p=0.832\n",
      "\u001b[0m\u001b[34mSample looks Gaussian (fail to reject H0)\n",
      "\u001b[0m\u001b[34m---------------------------------\n",
      "\u001b[0m\u001b[31mExclude participant(s): 4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyse()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
